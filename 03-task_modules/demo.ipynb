{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /data/user/nyf/pkgs/anaconda3/envs/loggpt did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('\"zh-cn\"},\"_languagePackId\"'), PosixPath('\"zh-cn\",\"availableLanguages\"'), PosixPath('\"/data/user/nyf/.vscode-server/data/clp/0860ebc1a1c97b3d555b187ac30e07fe.zh-cn\",\"_resolvedLanguagePackCoreLocation\"'), PosixPath('\"0860ebc1a1c97b3d555b187ac30e07fe.zh-cn\",\"_translationsConfigFile\"'), PosixPath('{\"*\"'), PosixPath('{\"locale\"'), PosixPath('\"zh-cn\",\"osLocale\"'), PosixPath('\"/data/user/nyf/.vscode-server/data/clp/0860ebc1a1c97b3d555b187ac30e07fe.zh-cn/corrupted.info\",\"_languagePackSupport\"'), PosixPath('\"/data/user/nyf/.vscode-server/data/clp/0860ebc1a1c97b3d555b187ac30e07fe.zh-cn/tcf.json\",\"_cacheRoot\"'), PosixPath('true}'), PosixPath('\"/data/user/nyf/.vscode-server/data/clp/0860ebc1a1c97b3d555b187ac30e07fe.zh-cn/af28b32d7e553898b2a91af498b1fb666fdebe0c\",\"_corruptedFile\"')}\n",
      "  warn(msg)\n",
      "/data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vscode-local'), PosixPath('/c%3A/Users/27512/.vscode/extensions/ms-ceintl.vscode-language-pack-zh-hans-1.85.2023120618/translations/extensions/vscode.json-language-features.i18n.json')}\n",
      "  warn(msg)\n",
      "/data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "2023-12-12 17:49:54.686894: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 17:49:55.028478: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-12 17:49:55.100974: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 17:49:56.515344: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-12 17:49:56.515532: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-12 17:49:56.515548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import datasets\n",
    "from nlplog import Config, FailurePredModel, FailurePredDataset\n",
    "from trainer import seed_everything, train_and_eval, test\n",
    "import pandas as pd\n",
    "from datasets import concatenate_datasets\n",
    "import copy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_from_disk('../data_hf/BGL/single/train_3611')\n",
    "test_20000_ds = load_from_disk('../data_hf/BGL/single/test_20000')\n",
    "test_302_all_ds = load_from_disk('../data_hf/BGL/single/all_302')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    256\n",
       "1     46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_302_all_ds.to_pandas().labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_failure_pred = Config(\n",
    "    wandb_project='failure_prediction',\n",
    "    wandb_enable=False,\n",
    "    single_linear_hidden_size=64,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    train_ratio=0.8,\n",
    "    lr=1e-4,\n",
    "    lr_scheduler='none',\n",
    "    warmup_steps=0,\n",
    "    early_stop=10,\n",
    "    weight_metric=False,\n",
    "    tqdm_disable=True,\n",
    "    confusion_matrix_enable=False,\n",
    "    train_data_file='../data/bgl/train80_bgl_structured_unique.csv',\n",
    "    test_data_file='../data/bgl/test20_bgl_structured_unique.csv',\n",
    "    random_state=1006\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_shuffle = train_ds.shuffle(seed=CFG_failure_pred.random_state)\n",
    "normal_train_ds = train_ds_shuffle.filter(lambda example: example['labels'] == 0)\n",
    "abnormal_train_ds = train_ds_shuffle.filter(lambda example: example['labels'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load dataset\n",
      "load dataloader\n",
      "/data/user/nyf/pkgs/anaconda3/envs/loggpt/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save best binary-f1 score: 0.6667 FailurePredModel\n",
      "Save best binary-f1 score: 0.6957 FailurePredModel\n",
      "Save best binary-f1 score: 0.7619 FailurePredModel\n",
      "Save best binary-f1 score: 0.9412 FailurePredModel\n",
      "Save best binary-f1 score: 1.0000 FailurePredModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stop and exit.\n",
      "================Test================\n",
      "confusion_matrix:\n",
      "[[12685  2421]\n",
      " [  236  4658]]\n",
      "[binary] precision: 0.6580 recall: 0.9518 f1: 0.7781\n",
      "[micro] precision: 0.8671 recall: 0.8671 f1: 0.8672\n",
      "[macro] precision: 0.8199 recall: 0.8958 f1: 0.8416\n"
     ]
    }
   ],
   "source": [
    "# 16 shots demo\n",
    "CFG_failure_pred.lr = 1e-4\n",
    "CFG_failure_pred.epochs = 200\n",
    "CFG_failure_pred.early_stop = 20\n",
    "CFG_failure_pred.best_model_metric = 'binary'\n",
    "CFG_failure_pred.single_linear_hidden_size = 256\n",
    "CFG_failure_pred.device = torch.device('cuda:0')\n",
    "CFG_failure_pred.batch_size = 16\n",
    "CFG_failure_pred.train_ratio = 1\n",
    "\n",
    "few_shots = concatenate_datasets([normal_train_ds.select(range(16//2)), abnormal_train_ds.select(range(16//2))])\n",
    "few_shots = few_shots.shuffle(seed=CFG_failure_pred.random_state)\n",
    "\n",
    "seed_everything(CFG_failure_pred.random_state)\n",
    "llm_hidden_size = 4096\n",
    "task_module = FailurePredModel(llm_hidden_size=llm_hidden_size, config=CFG_failure_pred)\n",
    "\n",
    "CFG_failure_pred.confusion_matrix_enable = False\n",
    "\n",
    "CFG_failure_pred.f1_report = ['binary']\n",
    "train_and_eval(task_module, FailurePredDataset, few_shots, CFG_failure_pred)\n",
    "\n",
    "CFG_failure_pred.confusion_matrix_enable = True\n",
    "CFG_failure_pred.f1_report = ['binary', 'micro', 'macro']\n",
    "\n",
    "# 20000 test\n",
    "report = test(task_module, FailurePredDataset, test_20000_ds, CFG_failure_pred, load_best_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loggpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
